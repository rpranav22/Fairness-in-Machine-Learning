{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FAIR.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3yi1BFzZ13aJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from google.colab import files\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics.pairwise import paired_euclidean_distances, euclidean_distances\n",
        "\n",
        "u = files.upload()\n",
        "\n",
        "def preprocess(data):\n",
        "    preprocess = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "    for feature in preprocess:\n",
        "        data[feature] = pd.cut(data[feature], 5, labels=(1, 2, 3, 4, 5))\n",
        "    # data[\"age\"] = pd.cut(data['age'] , 5, labels=(1,2,3,4,5))\n",
        "    \n",
        "    return data\n",
        "\n",
        "def split_data(data):\n",
        "#     msk = np.random.rand(len(data)) < 0.8\n",
        "#     train = data[msk]\n",
        "#     test = data[~msk]\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    train, test = train_test_split(data, test_size=0.2, shuffle=False)\n",
        "\n",
        "    Y_train = train['target'].to_frame()\n",
        "    X_train = train.drop('target', axis=1)\n",
        "    Y_test = test['target'].to_frame()\n",
        "    X_test = test.drop('target', axis=1)\n",
        "    return X_train,Y_train,X_test,Y_test\n",
        "\n",
        "def Clusters(data,k):\n",
        "    \n",
        "    dataset = data.values\n",
        "    \n",
        "    km = KMeans(n_clusters=k).fit(dataset)\n",
        "    \n",
        "    closest, _ = pairwise_distances_argmin_min(km.cluster_centers_, dataset)\n",
        "    \n",
        "    a=[]\n",
        "    \n",
        "    for x in closest:\n",
        "        a.append(dataset[x].tolist())\n",
        "    \n",
        "    return(a)\n",
        "\n",
        "def Main():\n",
        "    raw_data = pd.read_csv(\"heart.csv\")\n",
        "    data = preprocess(raw_data)\n",
        "    classifiers = ['Linear Svm', 'Radial Svm', 'Logistic Regression', 'KNN']\n",
        "\n",
        "    X_train, Y_train, X_test, Y_test = split_data(data)\n",
        "\n",
        "    abc4 = []\n",
        "    \n",
        "    models = [svm.SVC(kernel='linear'), svm.SVC(kernel='rbf'), LogisticRegression(),\n",
        "              KNeighborsClassifier(n_neighbors=3)]\n",
        "    \n",
        "    model = models[0]\n",
        "    model.fit(X_train, Y_train)\n",
        "    print(\"coeff {}\".format(model.coef_))\n",
        "    prediction = model.predict(X_test)\n",
        "    abc4.append(metrics.accuracy_score(prediction, Y_test))\n",
        "    \n",
        "    \n",
        "    X1=pd.DataFrame(columns=list(X_test.columns.values))\n",
        "    X0=pd.DataFrame(columns=list(X_test.columns.values))\n",
        "    \n",
        "    for x in range(len(prediction)):\n",
        "        if(prediction[x]==1):\n",
        "           X1 = X1.append(X_test.iloc[x])\n",
        "        else:\n",
        "           X0 = X0.append(X_test.iloc[x])\n",
        "    X_train['target'] = Y_train\n",
        "    X1_train = X_train.loc[X_train['target']==1].drop('target',axis=1)\n",
        "    X0_train = X_train.loc[X_train['target']==0].drop('target',axis=1)\n",
        "    X_train = X_train.drop('target',axis=1)\n",
        "    Centers1_train=Clusters(X1_train,3)\n",
        "    Centers0_train=Clusters(X0_train,3)\n",
        "            \n",
        "    \n",
        "    Centers1= Clusters(X1,3)\n",
        "    Centers= Centers1\n",
        "    Centers0= Clusters(X0,3)\n",
        "    Centers.extend(Centers0)\n",
        "    \n",
        "    y1=models[0].decision_function(X1)\n",
        "    y0 = models[0].decision_function(X0)\n",
        "\n",
        "    dists1 = np.array(y1)\n",
        "    dists0 = np.array(y0)\n",
        "    X1['dist'] = pd.DataFrame(dists1)\n",
        "    X0['dist'] = pd.DataFrame(dists0)\n",
        "\n",
        "    absdists1 = np.abs(dists1)\n",
        "    absdists0 = np.abs(dists0)\n",
        "    X1['abs'] = pd.DataFrame(absdists1)\n",
        "    X1_near = X1.sort_values(['abs'])[:5]\n",
        "    X0['abs'] = pd.DataFrame(absdists0)\n",
        "    X0_near = X0.sort_values(['abs'])[:5]\n",
        "    X0_near = X0_near.drop(['dist','abs'],axis=1)\n",
        "    X1_near = X1_near.drop(['dist','abs'],axis=1)\n",
        "    \n",
        "    print(X0_near)\n",
        "    print(X1_near)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    closest00= euclidean_distances(X0_near.values,Centers0_train)  \n",
        "    closest01 = euclidean_distances(X0_near.values,Centers1_train) \n",
        "    closest10 = euclidean_distances(X1_near.values,Centers0_train) \n",
        "    closest11= euclidean_distances(X1_near.values,Centers1_train)\n",
        "    \n",
        "    avg00= []\n",
        "    avg01=[]\n",
        "    avg10=[]\n",
        "    avg11=[]\n",
        "    \n",
        "    for i in range(5):\n",
        "        print(\"Unfair0\")\n",
        "        if(sum(closest00[i])/3 > sum(closest01[i])/3):\n",
        "           print(X0_near.iloc[i])\n",
        "        print(\"Unfair1\")\n",
        "        if(sum(closest10[i])/3 > sum(closest11[i])/3):\n",
        "           print(X0_near.iloc[i])\n",
        "   \n",
        "    \n",
        "        \n",
        "    \n",
        "    \n",
        "   \n",
        "    \n",
        "   # for i in range(5):\n",
        "   #     print(\"Unfair 0:\")\n",
        "   #     if(closest0[i]<5):\n",
        "   #        print(X0_near.iloc[[i]])\n",
        "   #     print(\"Unfair 1:\")\n",
        "   #     if(closest1[i]>5):\n",
        "   #        print(X1_near.iloc[[i]])\n",
        "        \n",
        "           \n",
        "     \n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UfRTytOoTrmF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from google.colab import files\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics.pairwise import paired_euclidean_distances, euclidean_distances\n",
        "\n",
        "u = files.upload()\n",
        "\n",
        "def preprocess(data):\n",
        "    preprocess = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
        "    for feature in preprocess:\n",
        "        data[feature] = pd.cut(data[feature], 5, labels=(1, 2, 3, 4, 5))\n",
        "    # data[\"age\"] = pd.cut(data['age'] , 5, labels=(1,2,3,4,5))\n",
        "    \n",
        "    return data\n",
        "\n",
        "def split_data(data):\n",
        "#     msk = np.random.rand(len(data)) < 0.8\n",
        "#     train = data[msk]\n",
        "#     test = data[~msk]\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    train, test = train_test_split(data, test_size=0.2, shuffle=False)\n",
        "\n",
        "    Y_train = train['target'].to_frame()\n",
        "    X_train = train.drop('target', axis=1)\n",
        "    Y_test = test['target'].to_frame()\n",
        "    X_test = test.drop('target', axis=1)\n",
        "    return X_train,Y_train,X_test,Y_test\n",
        "\n",
        "def Clusters(data,k):\n",
        "    \n",
        "    dataset = data.values\n",
        "    \n",
        "    km = KMeans(n_clusters=k).fit(dataset)\n",
        "    \n",
        "    closest, _ = pairwise_distances_argmin_min(km.cluster_centers_, dataset)\n",
        "    \n",
        "    a=[]\n",
        "    \n",
        "    for x in closest:\n",
        "        a.append(dataset[x].tolist())\n",
        "    \n",
        "    return(a)\n",
        "\n",
        "def Main():\n",
        "    raw_data = pd.read_csv(\"heart.csv\")\n",
        "    data = preprocess(raw_data)\n",
        "    classifiers = ['Linear Svm', 'Radial Svm', 'Logistic Regression', 'KNN']\n",
        "\n",
        "    X_train, Y_train, X_test, Y_test = split_data(data)\n",
        "\n",
        "    abc4 = []\n",
        "    \n",
        "    models = [svm.SVC(kernel='linear'), svm.SVC(kernel='rbf'), LogisticRegression(),\n",
        "              KNeighborsClassifier(n_neighbors=3)]\n",
        "    \n",
        "    model = models[0]\n",
        "    model.fit(X_train, Y_train)\n",
        "    print(\"coeff {}\".format(model.coef_))\n",
        "    prediction = model.predict(X_test)\n",
        "    abc4.append(metrics.accuracy_score(prediction, Y_test))\n",
        "    \n",
        "    \n",
        "    X1=pd.DataFrame(columns=list(X_test.columns.values))\n",
        "    X0=pd.DataFrame(columns=list(X_test.columns.values))\n",
        "    \n",
        "    for x in range(len(prediction)):\n",
        "        if(prediction[x]==1):\n",
        "           X1 = X1.append(X_test.iloc[x])\n",
        "        else:\n",
        "           X0 = X0.append(X_test.iloc[x])\n",
        "    X_train['target'] = Y_train\n",
        "    X1_train = X_train.loc[X_train['target']==1].drop('target',axis=1)\n",
        "    X0_train = X_train.loc[X_train['target']==0].drop('target',axis=1)\n",
        "    X_train = X_train.drop('target',axis=1)\n",
        "    Centers1_train=Clusters(X1_train,3)\n",
        "    Centers0_train=Clusters(X0_train,3)\n",
        "            \n",
        "    \n",
        "    Centers1= Clusters(X1,3)\n",
        "    Centers= Centers1\n",
        "    Centers0= Clusters(X0,3)\n",
        "    Centers.extend(Centers0)\n",
        "    \n",
        "    y1=models[0].decision_function(X1)\n",
        "    y0 = models[0].decision_function(X0)\n",
        "\n",
        "    dists1 = np.array(y1)\n",
        "    dists0 = np.array(y0)\n",
        "    X1['dist'] = pd.DataFrame(dists1)\n",
        "    X0['dist'] = pd.DataFrame(dists0)\n",
        "\n",
        "    absdists1 = np.abs(dists1)\n",
        "    absdists0 = np.abs(dists0)\n",
        "    X1['abs'] = pd.DataFrame(absdists1)\n",
        "    X1_near = X1.sort_values(['abs'])[:5]\n",
        "    X0['abs'] = pd.DataFrame(absdists0)\n",
        "    X0_near = X0.sort_values(['abs'])[:5]\n",
        "    X0_near = X0_near.drop(['dist','abs'],axis=1)\n",
        "    X1_near = X1_near.drop(['dist','abs'],axis=1)\n",
        "    \n",
        "    print(X0_near)\n",
        "    print(X1_near)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    closest00= euclidean_distances(X0_near.values,Centers0_train)  \n",
        "    closest01 = euclidean_distances(X0_near.values,Centers1_train) \n",
        "    closest10 = euclidean_distances(X1_near.values,Centers0_train) \n",
        "    closest11= euclidean_distances(X1_near.values,Centers1_train)\n",
        "    \n",
        "    avg00= []\n",
        "    avg01=[]\n",
        "    avg10=[]\n",
        "    avg11=[]\n",
        "    \n",
        "    for i in range(5):\n",
        "        print(\"Unfair0\")\n",
        "        if(sum(closest00[i])/3 > sum(closest01[i])/3):\n",
        "           print(X0_near.iloc[i])\n",
        "        print(\"Unfair1\")\n",
        "        if(sum(closest10[i])/3 > sum(closest11[i])/3):\n",
        "           print(X0_near.iloc[i])\n",
        "   \n",
        "    \n",
        "        \n",
        "    \n",
        "    \n",
        "   \n",
        "    \n",
        "   # for i in range(5):\n",
        "   #     print(\"Unfair 0:\")\n",
        "   #     if(closest0[i]<5):\n",
        "   #        print(X0_near.iloc[[i]])\n",
        "   #     print(\"Unfair 1:\")\n",
        "   #     if(closest1[i]>5):\n",
        "   #        print(X1_near.iloc[[i]])\n",
        "        \n",
        "           \n",
        "     \n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    Main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-3dHk_RLvtM",
        "colab_type": "code",
        "outputId": "9695fdf5-2e69-4115-cbc5-5412c947c7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from numpy.random import binomial\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import load_iris\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics.pairwise import paired_euclidean_distances, euclidean_distances\n",
        "from sklearn import svm\n",
        "\n",
        "def Clusters(data,k):    \n",
        "      \n",
        "    km = KMeans(n_clusters=k).fit(data)    \n",
        "    closest, _ = pairwise_distances_argmin_min(km.cluster_centers_, data)    \n",
        "    a=[]    \n",
        "    for x in closest:\n",
        "        a.append(data[x].tolist())    \n",
        "    return(a)\n",
        "\n",
        "df = pd.read_csv(\"Iris.csv\")\n",
        "df.loc[df.Species == 'Iris-setosa', 'Species'] = 1\n",
        "df.loc[df.Species == 'Iris-versicolor', 'Species'] = 2\n",
        "df = df[df.Species != 'Iris-virginica'] \n",
        "df = df.drop(\"Id\",axis=1)\n",
        "\n",
        "#g = sns.pairplot(df, hue='Species', markers='+')\n",
        "#plt.show()\n",
        "\n",
        "s = binomial(1,0.5,len(df))\n",
        "\n",
        "df[\"new\"] = s\n",
        "\n",
        "train_values = df.sample(frac=0.6).astype(float)\n",
        "test_values = df.sample(frac=0.4).astype(float)\n",
        "\n",
        "#print(test_values.loc[test_values.SepalLengthCm >6.5].loc[test_values.new == 1])\n",
        "\n",
        "train_inputs = train_values.as_matrix(columns=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm','new']).astype(float)\n",
        "train_predicts = train_values['Species'].values.astype(int)\n",
        "\n",
        "test_inputs = test_values.as_matrix(columns=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm','new']).astype(float)\n",
        "test_predicts = test_values['Species'].values.astype(int)\n",
        "\n",
        "#print(test_inputs)\n",
        "\n",
        "model = svm.SVC(kernel='linear')\n",
        "model.fit(train_inputs, train_predicts)\n",
        "\n",
        "train_predicted_values = model.predict(train_inputs)\n",
        "\n",
        "accuracy = metrics.accuracy_score(train_predicts, train_predicted_values) * 100\n",
        "#print('Training Accuracy {0:0.4f}%'.format(accuracy))\n",
        "\n",
        "test_predicted_values = model.predict(test_inputs)\n",
        "\n",
        "count=-1\n",
        "for i in test_inputs:\n",
        "    count+=1\n",
        "    if(i[0]>6.5):\n",
        "      if(i[4]==1):\n",
        "        test_predicted_values[count]=1\n",
        "        \n",
        "x1_train=[]\n",
        "x0_train=[]\n",
        "\n",
        "for i in range(len(train_inputs)):\n",
        "    if(train_predicts[i]==1):\n",
        "       x1_train.append(train_inputs[i])\n",
        "    else:\n",
        "       x0_train.append(train_inputs[i])\n",
        "       \n",
        "x0_test=[]\n",
        "x1_test=[]\n",
        "for i in range(len(test_inputs)):\n",
        "    if(test_predicted_values[i]==1):\n",
        "       x1_test.append(test_inputs[i])\n",
        "    else:\n",
        "       x0_test.append(test_inputs[i])\n",
        "\n",
        "\n",
        "Centers1 = Clusters(x1_train,5)\n",
        "Centers0 = Clusters(x0_train,5)\n",
        "print(type(Centers1), Centers0)\n",
        "d0 = model.decision_function(x0_test)\n",
        "d1 = model.decision_function(x1_test)\n",
        "\n",
        "dists1 = np.array(d1)\n",
        "dists0 = np.array(d0)\n",
        "\n",
        "absdists1 = np.abs(dists1)\n",
        "absdists0 = np.abs(dists0)\n",
        "\n",
        "req1 = np.argsort(absdists1)\n",
        "req0 = np.argsort(absdists0)\n",
        "\n",
        "a1 = [x1_test[x] for x in req1[:5]]\n",
        "a0 = [x0_test[x] for x in req0[:5]]\n",
        "\n",
        "\n",
        "closest00 = euclidean_distances(a0,Centers0)  \n",
        "print(\"center0: {} ,\\n closest00: {}\".format(Centers0, closest00))\n",
        "closest01 = euclidean_distances(a0,Centers1) \n",
        "closest10 = euclidean_distances(a1,Centers0) \n",
        "closest11= euclidean_distances(a1,Centers1)\n",
        "\n",
        "\n",
        "   \n",
        "for i in range(5):\n",
        "        print(\"Unfair0\")\n",
        "        if(sum(closest00[i])/5 > sum(closest01[i])/5):\n",
        "           print(a0[1])\n",
        "        print(\"Unfair1\")\n",
        "        if(sum(closest10[i])/5 > sum(closest11[i])/5):\n",
        "           print(a1[i])\n",
        "           \n",
        "\n",
        "#print(Centers)\n",
        "accuracy = metrics.accuracy_score(test_predicts, test_predicted_values) * 100\n",
        "#print('Testing Accuracy {0:0.4f}%'.format(accuracy))\n",
        "\n",
        "\n",
        "#print(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'> [[5.0, 2.3, 3.3, 1.0, 1.0], [6.4, 3.2, 4.5, 1.5, 1.0], [5.7, 2.8, 4.1, 1.3, 0.0], [5.6, 2.7, 4.2, 1.3, 1.0], [6.3, 2.3, 4.4, 1.3, 0.0]]\n",
            "center0: [[5.0, 2.3, 3.3, 1.0, 1.0], [6.4, 3.2, 4.5, 1.5, 1.0], [5.7, 2.8, 4.1, 1.3, 0.0], [5.6, 2.7, 4.2, 1.3, 1.0], [6.3, 2.3, 4.4, 1.3, 0.0]] ,\n",
            " closest00: [[0.64807407 1.52970585 1.20415946 0.66332496 1.49331845]\n",
            " [1.4832397  1.43527001 0.26457513 1.06770783 0.81853528]\n",
            " [1.2        1.00995049 1.05356538 0.37416574 1.26095202]\n",
            " [1.68226038 1.30766968 0.24494897 1.05356538 0.9486833 ]\n",
            " [1.50332964 1.43527001 0.26457513 1.04880885 0.71414284]]\n",
            "Unfair0\n",
            "Unfair1\n",
            "[5.1 3.3 1.7 0.5 1. ]\n",
            "Unfair0\n",
            "Unfair1\n",
            "[4.8 3.1 1.6 0.2 1. ]\n",
            "Unfair0\n",
            "Unfair1\n",
            "[5.  3.5 1.6 0.6 0. ]\n",
            "Unfair0\n",
            "Unfair1\n",
            "[5.4 3.4 1.7 0.2 1. ]\n",
            "Unfair0\n",
            "Unfair1\n",
            "[4.8 3.  1.4 0.3 1. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7sIDrQ7SKvdd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Creating the new data set  ( Iris + Binomial var)"
      ]
    },
    {
      "metadata": {
        "id": "QF4gvpQKKujS",
        "colab_type": "code",
        "outputId": "8c560203-55f6-4867-ee31-1229ab4c2d34",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1f320ee0-1b53-4a7b-9a0f-c79c1bf13cdd\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-1f320ee0-1b53-4a7b-9a0f-c79c1bf13cdd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Iris.csv to Iris.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hutED_1lXwN3",
        "colab_type": "code",
        "outputId": "ad39dd9a-a560-4099-a0dc-8c65a8cdd1ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from numpy.random import binomial\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import load_iris\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "from sklearn.metrics.pairwise import paired_euclidean_distances, euclidean_distances\n",
        "from sklearn import svm\n",
        "\n",
        "df = pd.read_csv(\"Iris.csv\")\n",
        "df.loc[df.Species == 'Iris-setosa', 'Species'] = 1\n",
        "df.loc[df.Species == 'Iris-versicolor', 'Species'] = 2\n",
        "df = df[df.Species != 'Iris-virginica'] \n",
        "df = df.drop(\"Id\",axis=1)\n",
        "\n",
        "#g = sns.pairplot(df, hue='Species', markers='+')\n",
        "#plt.show()\n",
        "\n",
        "s = binomial(1,0.5,len(df))\n",
        "\n",
        "df[\"new\"] = s\n",
        "\n",
        "train_values = df.sample(frac=0.6).astype(float)\n",
        "test_values = df.sample(frac=0.4).astype(float)\n",
        "\n",
        "#print(test_values.loc[test_values.SepalLengthCm >6.5].loc[test_values.new == 1])\n",
        "\n",
        "train_inputs = train_values.as_matrix(columns=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm','new']).astype(float)\n",
        "train_predicts = train_values['Species'].values.astype(int)\n",
        "\n",
        "test_inputs = test_values.as_matrix(columns=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm','new']).astype(float)\n",
        "test_predicts = test_values['Species'].values.astype(int)\n",
        "\n",
        "\n",
        "\n",
        "#print(test_inputs)\n",
        "\n",
        "model = svm.SVC(kernel='linear')\n",
        "model.fit(train_inputs, train_predicts)\n",
        "\n",
        "train_predicted_values = model.predict(train_inputs)\n",
        "\n",
        "accuracy = metrics.accuracy_score(train_predicts, train_predicted_values) * 100\n",
        "#print('Training Accuracy {0:0.4f}%'.format(accuracy))\n",
        "\n",
        "test_predicted_values = model.predict(test_inputs)\n",
        "\n",
        "count=-1\n",
        "for i in test_inputs:\n",
        "    count+=1\n",
        "    if(i[3]>0.5):\n",
        "      if(i[4]==1):\n",
        "        print(i)\n",
        "        test_predicted_values[count]=1\n",
        "        \n",
        "x1_train=[]\n",
        "x0_train=[]\n",
        "\n",
        "for i in range(len(train_inputs)):\n",
        "    if(train_predicts[i]==1):\n",
        "       x1_train.append(train_inputs[i])\n",
        "    else:\n",
        "       x0_train.append(train_inputs[i])\n",
        "       \n",
        "x0_test=[]\n",
        "x1_test=[]\n",
        "for i in range(len(test_inputs)):\n",
        "    if(test_predicted_values[i]==1):\n",
        "       x1_test.append(test_inputs[i])\n",
        "    else:\n",
        "       x0_test.append(test_inputs[i])\n",
        "\n",
        "\n",
        "#Centers1 = Clusters(x1_train,5)\n",
        "#Centers0 = Clusters(x0_train,5)\n",
        "\n",
        "d0 = model.decision_function(x0_test)\n",
        "d1 = model.decision_function(x1_test)\n",
        "\n",
        "dists1 = np.array(d1)\n",
        "dists0 = np.array(d0)\n",
        "\n",
        "absdists1 = np.abs(dists1)\n",
        "absdists0 = np.abs(dists0)\n",
        "print(absdists0)\n",
        "\n",
        "req1 = np.argsort(absdists1)\n",
        "req0 = np.argsort(absdists0)\n",
        "\n",
        "# /print(\"req1: {}\".format(req1))\n",
        "\n",
        "a1 = [x1_test[x] for x in req1[:5]]\n",
        "a0 = [x0_test[x] for x in req0[:5]]\n",
        "\n",
        "\n",
        "#Running only for points in a1\n",
        "dist_pts =  euclidean_distances(a0, train_inputs)\n",
        "# print(\"closest: {}\".format(dist_pts))\n",
        "close=[]\n",
        "for x in dist_pts:\n",
        "  \n",
        "  np_x = np.array(x)\n",
        "  re = np.argsort(np_x)\n",
        "  close.append(re[:40])\n",
        "  print(re)\n",
        "  \n",
        "#Check if test_predicts will have same index as x_test in this case\n",
        "# print(close)\n",
        "print(\"xtrain {} xtest {} trainpred {} test pred {}\".format(len(train_inputs), len(test_inputs), len(train_predicts), len(test_predicts)))\n",
        "close_preds=[]\n",
        "print(train_predicts)\n",
        "#classes of the top k points\n",
        "\n",
        "for x in close:\n",
        "#   print(x)\n",
        "  check= []\n",
        "  for t in x:\n",
        "    #print(t)\n",
        "    \n",
        "    check.append(train_predicts[t])\n",
        "#     print(test_predicts[t])\n",
        "  print(check)\n",
        "  close_preds.append(check)\n",
        "  \n",
        "  #Normal voting\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.5 2.8 4.6 1.5 1. ]\n",
            "[6.6 2.9 4.6 1.3 1. ]\n",
            "[6.  2.7 5.1 1.6 1. ]\n",
            "[6.8 2.8 4.8 1.4 1. ]\n",
            "[5.7 3.  4.2 1.2 1. ]\n",
            "[6.1 2.8 4.7 1.2 1. ]\n",
            "[5.8 2.7 3.9 1.2 1. ]\n",
            "[5.6 2.5 3.9 1.1 1. ]\n",
            "[6.7 3.1 4.7 1.5 1. ]\n",
            "[5.6 3.  4.5 1.5 1. ]\n",
            "[6.9 3.1 4.9 1.5 1. ]\n",
            "[2.16484756 2.04468884 2.48541997 3.23356147 1.96238325 1.950744\n",
            " 2.67339924 2.38040728 1.19975768 2.56315477 2.94667533 2.0711157 ]\n",
            "[29 22 53 40  6  4 58 26 20  8 48 54  7 37 35 16 32 47 52 14 21 11  2 39\n",
            " 18 34  1 59 19 25 50 55 23 28 17 41 24 15  3  9 43 45 51 36 38 12 31 57\n",
            " 46 49 13 56 27 10  0 42  5 30 33 44]\n",
            "[58  4 26 40 35 14 21 53 22  1 37  7 17 32 48 47 16  8 54 20  2 50 19 59\n",
            " 29 56 12 10  6 42 39 52 18 11 28 51 24 36 34 23 15 43 57 46 55 38 13 27\n",
            "  9 45 31 49 41  3 25 44  5 33  0 30]\n",
            "[26  4 58 40 22 53 35 14 16  1 21 48 20 37  7 50 54  2 17 32  8 19 59 47\n",
            " 29 12 56 10  6 42 39 52 18 11 28 34 23 51 24 36 15 55 57 43 38  9 46 13\n",
            " 27 45 25 41 49  3 31  5 44 33  0 30]\n",
            "[ 4 26 58 40 22 53 35 14 16 48  1 20 21  7 50 37 54  8 32  2 17 29 47 59\n",
            " 19 12 56  6 10 42 39 52 18 11 28 34 23 24 51 36 15 55 57 43  9 38 46 13\n",
            " 45 25 27 41 49  3 31  5 44 33  0 30]\n",
            "[58  4 26 40 35 22 14 53 21 16  1  7 37 17 48 32 50 54 20 47  8  2 19 59\n",
            " 29 56 12 10  6 42 39 52 18 11 28 24 34 51 23 36 15 55 57 43 46 38  9 13\n",
            " 27 45 25 41 49 31  3  5 44 33  0 30]\n",
            "xtrain 60 xtest 40 trainpred 60 test pred 40\n",
            "[1 2 2 1 2 1 2 2 2 1 2 1 2 1 2 1 2 2 1 2 2 2 2 1 1 1 2 1 1 2 1 1 2 1 1 2 1\n",
            " 2 1 1 2 1 2 1 1 1 1 2 2 1 2 1 1 2 2 1 2 1 2 2]\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1]\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "28pemsBREAEJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This section is test on the two new data sets cod-rna and german-numer\n"
      ]
    },
    {
      "metadata": {
        "id": "46kBy2yH-8W6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#new data set cod-rna\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y__9xbPBd7fK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import svm, metrics\n",
        "from sklearn.metrics import euclidean_distances\n",
        "\n",
        "\n",
        "def load_data(dataset):\n",
        "\n",
        "    if dataset == \"german\":\n",
        "        data_german = pd.read_csv('german.numer.txt', sep=\" \", header=None)\n",
        "        data_german.columns = [\"Target\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\", \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\", \"0\"]\n",
        "        data_german = data_german.drop(\"0\", axis=1)\n",
        "        for i in range(1,25):\n",
        "            if i >9:\n",
        "                data_german[str(i)] = data_german[str(i)].apply(lambda x: float(str(x)[3:]))\n",
        "            else:\n",
        "                data_german[str(i)] = data_german[str(i)].apply(lambda x: float(str(x)[2:]))\n",
        "        # print(data_german.head())\n",
        "        return data_german\n",
        "\n",
        "    elif dataset == \"cod\":\n",
        "        data_cod = pd.read_csv('cod-rna.txt', sep=\" \", header=None)\n",
        "        data_cod.columns = [\"Target\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]\n",
        "        for i in range(1,9):\n",
        "            data_cod[str(i)] = data_cod[str(i)].apply(lambda x: float(str(x)[2:]))\n",
        "\n",
        "        # print(data_cod.head())\n",
        "        return data_cod\n",
        "\n",
        "      \n",
        "def Main():    \n",
        "    data = load_data(\"cod\")\n",
        "\n",
        "    train_values = data.sample(frac=0.6).astype(float)\n",
        "    test_values = data.sample(frac=0.4).astype(float)\n",
        "    y_train = train_values['Target'].values.astype(int)\n",
        "    y_test = test_values['Target'].values.astype(int)\n",
        "    train_values = train_values.drop('Target', axis=1)\n",
        "    test_values = test_values.drop('Target', axis=1)\n",
        "\n",
        "    train_values = train_values.as_matrix().astype(float)\n",
        "    test_values = test_values.as_matrix().astype(float)\n",
        "\n",
        "    print(data.head())\n",
        "\n",
        "    # model = svm.SVC(kernel='linear')\n",
        "    # model.fit(train_values, y_train)\n",
        "    #\n",
        "    filename = 'cod_svm.sav'\n",
        "    # pickle.dump(model, open(filename, 'wb'))\n",
        "\n",
        "    model = pickle.load(open(filename, 'rb'))\n",
        "    train_predicted_values = model.predict(train_values)\n",
        "    # print(y_train)\n",
        "    # print(len(train_predicted_values))\n",
        "\n",
        "    accuracy = metrics.accuracy_score(y_train, train_predicted_values) * 100\n",
        "    print('Training Accuracy {0:0.4f}%'.format(accuracy))\n",
        "\n",
        "    test_predicted_values = model.predict(test_values)\n",
        "\n",
        "    x1_train = []\n",
        "    x0_train = []\n",
        "    # print(train_values)\n",
        "    for i in range(len(train_values)):\n",
        "        # print(train_values[i])\n",
        "        if (y_train[i] == 1):\n",
        "            x1_train.append(train_values[i])\n",
        "        else:\n",
        "            x0_train.append(train_values[i])\n",
        "\n",
        "    x0_test = []\n",
        "    x1_test = []\n",
        "    for i in range(len(test_values)):\n",
        "        if (test_predicted_values[i] == 1):\n",
        "            x1_test.append(test_values[i])\n",
        "        else:\n",
        "            x0_test.append(test_values[i])\n",
        "\n",
        "    # print(\"Finished x_0 {} and \\n x_1{}\".format(x0_train, x1_train))\n",
        "\n",
        "    # Distances from the decision boundar for points of each class\n",
        "    d0 = model.decision_function(x0_test)\n",
        "    d1 = model.decision_function(x1_test)\n",
        "\n",
        "    dists1 = np.array(d1)\n",
        "    dists0 = np.array(d0)\n",
        "\n",
        "    absdists1 = np.abs(dists1)\n",
        "    absdists0 = np.abs(dists0)\n",
        "    # print(absdists0)\n",
        "\n",
        "    # sorted order of points that are closest to the decision boundary from each class\n",
        "    req1 = np.argsort(absdists1)\n",
        "    req0 = np.argsort(absdists0)\n",
        "\n",
        "    # /print(\"req1: {}\".format(req1))\n",
        "    # top 5 points from each class to the decision boundary\n",
        "    a1 = [x1_test[x] for x in req1[:10]]\n",
        "    a0 = [x0_test[x] for x in req0[:10]]\n",
        "\n",
        "    print(\"closest points: {}\".format(a1))\n",
        "\n",
        "    # Running only for points in a1\n",
        "    dist_pts = euclidean_distances(a1, train_values)\n",
        "    # print(\"closest: {}\".format(dist_pts))\n",
        "    close = []\n",
        "    for x in dist_pts:\n",
        "        np_x = np.array(x)\n",
        "        re = np.argsort(np_x)\n",
        "        close.append(re[:10])\n",
        "        # print(re)\n",
        "\n",
        "    # Check if test_predicts will have same index as x_test in this case\n",
        "    close_preds = []\n",
        "    # print(train_predicts)\n",
        "    # classes of the top k points\n",
        "\n",
        "    for x in close:\n",
        "        #   print(x)\n",
        "        check = []\n",
        "        for t in x:\n",
        "            # print(t)\n",
        "\n",
        "            check.append(y_train[t])\n",
        "        #     print(test_predicts[t])\n",
        "        # print(check)\n",
        "        close_preds.append(check)\n",
        "        # print(len(close_preds))\n",
        "\n",
        "    for pts in close_preds:\n",
        "        n1 = 0\n",
        "        for x in pts:\n",
        "            if x == 1:\n",
        "                n1 += 1\n",
        "        if n1 > len(pts) / 2:\n",
        "            print(\"This point is fairly classified: {}\".format(pts))\n",
        "        else:\n",
        "            print(\"This point s unfairly classified {}\".format(pts))\n",
        "\n",
        "Main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}