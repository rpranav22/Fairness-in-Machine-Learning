# Examining Individual Unfairness in MAchine Learning
## Abstract
We aim to create a methodology to identify individual unfairness after the classification process is complete. Our approach
involves the development of a distance metric to quantify the similarity between two individuals as well as the metric to quantify the conditions in which an individual is treated unfairly. This is in accordance with our definition of unfairness which is as follows: 
An individual is treated unfairly when a significant proportion of other similar individuals are categorized differently. This semester we explore the different approaches to fairness in order to create a novel definition that is not based on protecting sensitive attributes using our learning we aim to optimize the distance metric in order to create a general framework to identify unfairness and proceed with our project.
